{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:39:41.867101Z",
     "start_time": "2025-01-09T10:39:36.589251Z"
    }
   },
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from nlp_chat_bot.model.minilm import MiniLM\n",
    "from nlp_chat_bot.rag.classic_rag import ClassicRAG\n",
    "from nlp_chat_bot.vector_store.chroma_vector_store_builder import ChromaVectorStoreBuilder"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:39:41.898745Z",
     "start_time": "2025-01-09T10:39:41.873227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:39:45.414591Z",
     "start_time": "2025-01-09T10:39:41.957625Z"
    }
   },
   "source": [
    "dataset_path = \"../data\"\n",
    "vector_store_path = \"../chromadb\"\n",
    "model_download_path = \"../models\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=50,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "\n",
    "embedding_function = MiniLM(model_download_path=model_download_path)\n",
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "document_loader = None\n",
    "vector_store = ChromaVectorStoreBuilder(dataset_path,\n",
    "                                        embedding_function,\n",
    "                                        vector_store_path,\n",
    "                                        splitter).build(False)\n",
    "rag = ClassicRAG(vector_store, llm_gemini)\n",
    "\n",
    "print(\"LENGTH\", rag.get_num_docs())\n",
    "docs_retrieved = rag.retrieve(state = {\"question\": \"What is my conclusion in my project report on image inpainting?\", \"context\": []})\n",
    "\n",
    "print(\"Num docs:\", len(docs_retrieved[\"context\"]))\n",
    "\n",
    "for i in range(len(docs_retrieved[\"context\"])):\n",
    "    doc = docs_retrieved[\"context\"][i]\n",
    "    print(\"\\n\\n\", \"#\"*30,\"\\n\")\n",
    "    print(f\"doc {i}: (score: {doc.metadata['score']})\")\n",
    "    print(doc.page_content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\nlp_project_chatbot\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH 1589\n",
      "Num docs: 3\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 0: (score: 0.903975248336792)\n",
      "Image Inpainting with Basic Convolutional Networks\n",
      "Robin Meneust, Ethan Pinto\n",
      "December 2024\n",
      "1 Introduction\n",
      "In the context of our ”AI-Based Image Processing”\n",
      "course, we worked on this project, in which we repro-\n",
      "duced and tested a specific image inpainting approach,\n",
      "defined by the paper ”Context Encoders: Feature Learn-\n",
      "ing by Inpainting”(Pathak et al., 2016)[1].\n",
      "Image inpainting consists of filling hole(s) in an im-\n",
      "age. There exist different methods to do so (e.g. they\n",
      "compared their results with Photoshop). In this paper,\n",
      "they used a context encoder trained in an adversarial\n",
      "way. Basically there is a generator, this is our context\n",
      "encoder (here an encoder and a decoder) that given an\n",
      "image of size 128x128 with a dropout region (a ”hole”,\n",
      "with values set to 0) tries to predict what should be inside\n",
      "the hole. We focused on the simplest case here for the\n",
      "dropout region: a square in the center of size 64x64 (i.e.\n",
      "half of the image). This is a large section of the image,\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 1: (score: 1.0136408805847168)\n",
      "realistic, not just the missing regions”. So it will be\n",
      "sharper than with the reconstruction loss, as we can see\n",
      "in their paper in the figure 1. It’s basically BCE (Bi-\n",
      "nary Cross Entropy) loss. Note here that the encoder\n",
      "only considers the masked region (dropout) and not the\n",
      "whole image. This isn’t really clear in the loss section of\n",
      "the paper, but it is on their model architecture image,\n",
      "here in figure 2, since the discriminator input is 64x64\n",
      "while the full image is 128x128.\n",
      "In this report, we will first explain how we imple-\n",
      "mented the model as it’s defined in the paper in section 2.\n",
      "1https://github.com/Hanabi-TheFox/\n",
      "Image-Inpainting-with-Basic-Convolutional-Networks\n",
      "Figure 1: Comparison of Inpainting Results Using Rec,\n",
      "Adv or Joint Loss (Results From the Paper)\n",
      "Then we will describe our experiments setup (datasets,\n",
      "hyper-parameters...)3. Finally, we will present and in-\n",
      "terpret our results for the tests that we conducted in the\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 2: (score: 1.3105616569519043)\n",
      "is missing. However, it’s too blurry, so we tried increas-\n",
      "ing the weight of the adversarial loss. The results are in\n",
      "figure 4. Here there is almost no blur and the results are\n",
      "very similar to the ones in the paper, even though it’s\n",
      "not perfect.\n",
      "The two others are on Tiny ImageNet. We tried set-\n",
      "ting the same weight for adversarial and reconstruction\n",
      "Figure 3: Experiment on ImageNet 128x128 with Stan-\n",
      "dard Parameters (×1000 Ratio)\n",
      "Figure 4: Experiment on ImageNet 128x128 with ×200\n",
      "Ratio\n",
      "loss for once in figure 5. The results were to be expected,\n",
      "and are aligned with the original paper results (on adver-\n",
      "sarial loss only). The context doesn’t seem to be taken\n",
      "into account, the results are not blurry but are totally\n",
      "off compared to what we want. Note that compared to\n",
      "ImageNet-1k, we obtained quite good results with the\n",
      "parameters of the paper in figure 6.\n",
      "No matter the experiment, we always observed some\n",
      "errors on especially difficult images. That is for example\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T10:39:46.829944Z",
     "start_time": "2025-01-09T10:39:45.431256Z"
    }
   },
   "cell_type": "code",
   "source": "rag.invoke(query={\"question\":\"What is my conclusion in my project report on image inpainting?\"})[\"answer\"]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The provided text describes the implementation and experimental results of an image inpainting project using a context encoder.  The experiments showed that increasing the adversarial loss weight improved results, achieving results similar to the original paper, although not perfect.  Some errors persisted, especially on difficult images, regardless of the experiment.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
