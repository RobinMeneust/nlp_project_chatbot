{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Naive Chunking\n",
    "\n",
    "Apply chunking and THEN compute embeddings.\n",
    "\n",
    "Here the result is incorrect. You can compare it to late chunking to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:17:25.377007Z",
     "start_time": "2025-01-13T23:17:19.583601Z"
    }
   },
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from nlp_chat_bot.model.embedding.minilm import MiniLM\n",
    "from nlp_chat_bot.rag.classic_rag import ClassicRAG\n",
    "from nlp_chat_bot.vector_store.naive_chunking_chroma_vector_store_builder import NaiveChunkingChromaVectorStoreBuilder"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\nlp_project_chatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:17:25.392644Z",
     "start_time": "2025-01-13T23:17:25.377007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:17:29.941782Z",
     "start_time": "2025-01-13T23:17:25.612440Z"
    }
   },
   "source": [
    "dataset_path = \"../data\"\n",
    "vector_store_path = \"../chromadb\"\n",
    "model_download_path = \"../models\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=50,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "\n",
    "embedding_function = MiniLM(model_download_path=model_download_path)\n",
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "document_loader = None\n",
    "vector_store = NaiveChunkingChromaVectorStoreBuilder(dataset_path,\n",
    "                                        embedding_function,\n",
    "                                        vector_store_path,\n",
    "                                        splitter).build()\n",
    "rag = ClassicRAG(vector_store, llm_gemini)\n",
    "\n",
    "print(\"LENGTH\", rag.get_num_docs())\n",
    "docs_retrieved = rag.retrieve(state = {\"question\": \"What is my conclusion in my project report?\", \"context\": []})\n",
    "\n",
    "print(\"Num docs:\", len(docs_retrieved[\"context\"]))\n",
    "\n",
    "\n",
    "for i in range(len(docs_retrieved[\"context\"])):\n",
    "    doc = docs_retrieved[\"context\"][i]\n",
    "    print(\"\\n\\n\", \"#\"*30,\"\\n\")\n",
    "    print(f\"doc {i}: (score: {doc.metadata['score']})\")\n",
    "    print(doc.page_content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "0it [00:00, ?it/s]\n",
      "Storing documents embeddings (batch size is 1000): 0it [00:00, ?it/s]\n",
      "d:\\Programs\\Anaconda\\envs\\nlp_project_chatbot\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents are now loaded\n",
      "LENGTH 35\n",
      "Num docs: 3\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 0: (score: 1.6559454535018854)\n",
      "Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view\n",
      "\n",
      "This page was last edited on 12 December 2024, at 00:08 (UTC).\n",
      "\n",
      "Text is available under the Creative Commons Attribution-ShareAlike 4.0 License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
      "\n",
      "Contents\n",
      "\n",
      "hide\n",
      "\n",
      "(Top)\n",
      "\n",
      "Background\n",
      "\n",
      "Capabilities\n",
      "\n",
      "Corporate customization\n",
      "\n",
      "GPT-4o mini\n",
      "\n",
      "Scarlett Johansson controversy\n",
      "\n",
      "See also\n",
      "\n",
      "References\n",
      "\n",
      "GPT-4o\n",
      "\n",
      "17 languages\n",
      "\n",
      "Article Talk Read Edit View history\n",
      "\n",
      "Tools\n",
      "\n",
      "Appearance\n",
      "\n",
      "hide\n",
      "\n",
      "Text\n",
      "\n",
      "Width\n",
      "\n",
      "Color (beta)\n",
      "\n",
      "Small\n",
      "\n",
      "Standard\n",
      "\n",
      "Large\n",
      "\n",
      "Standard\n",
      "\n",
      "Wide\n",
      "\n",
      "Automatic\n",
      "\n",
      "Light\n",
      "\n",
      "Dark\n",
      "\n",
      "Generative Pre-trained Transformer\n",
      "\n",
      "4 Omni (GPT-4o)\n",
      "\n",
      "Developer(s) OpenAI\n",
      "\n",
      "Initial release May 13, 2024; 7 months ago\n",
      "\n",
      "Predecessor GPT-4 Turbo\n",
      "\n",
      "Successor OpenAI o1\n",
      "\n",
      "Type Multimodal\n",
      "\n",
      "Large language model\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 1: (score: 1.6589277118064476)\n",
      "Retrieved 2024-05-17.\n",
      "\n",
      "14. ^ \"OpenAI Platform\" . platform.openai.com. Retrieved 2024-11-29.\n",
      "\n",
      "15. ^\n",
      "\n",
      "\"Models - OpenAI API\" . OpenAI. Retrieved 17 May 2024.\n",
      "\n",
      "16. ^\n",
      "\n",
      "Conway, Adam (2024-05-13). \"What is GPT-4o? Everything you need to know about the new OpenAI model that everyone can use for\n",
      "\n",
      "free\" . XDA Developers. Retrieved 2024-05-17.\n",
      "\n",
      "17. ^ \"Models\" .\n",
      "\n",
      "18. ^ Franzen, Carl (2024-05-13). \"OpenAI announces new free model GPT-4o and ChatGPT for desktop\" . VentureBeat. Retrieved\n",
      "\n",
      "2024-05-18.\n",
      "\n",
      "19. ^\n",
      "\n",
      "\"OpenAI lets companies customise its most powerful AI model\" . South China Morning Post. 2024-08-21. Retrieved 2024-08-22.\n",
      "\n",
      "20. ^ \"OpenAI to Let Companies Customize Its Most Powerful AI Model\" . Bloomberg. 2024-08-20. Retrieved 2024-08-22.\n",
      "\n",
      "21. ^ The Hindu Bureau (2024-08-21). \"OpenAI will let businesses customise GPT-4o for specific use cases\" . The Hindu. ISSN 0971-751X .\n",
      "\n",
      "Retrieved 2024-08-22.\n",
      "\n",
      "22. ^\n",
      "\n",
      "\n",
      " ############################## \n",
      "\n",
      "doc 2: (score: 1.7256411192292145)\n",
      "is missing. However, it’s too blurry, so we tried increas-\n",
      "ing the weight of the adversarial loss. The results are in\n",
      "figure 4. Here there is almost no blur and the results are\n",
      "very similar to the ones in the paper, even though it’s\n",
      "not perfect.\n",
      "The two others are on Tiny ImageNet. We tried set-\n",
      "ting the same weight for adversarial and reconstruction\n",
      "Figure 3: Experiment on ImageNet 128x128 with Stan-\n",
      "dard Parameters (×1000 Ratio)\n",
      "Figure 4: Experiment on ImageNet 128x128 with ×200\n",
      "Ratio\n",
      "loss for once in figure 5. The results were to be expected,\n",
      "and are aligned with the original paper results (on adver-\n",
      "sarial loss only). The context doesn’t seem to be taken\n",
      "into account, the results are not blurry but are totally\n",
      "off compared to what we want. Note that compared to\n",
      "ImageNet-1k, we obtained quite good results with the\n",
      "parameters of the paper in figure 6.\n",
      "No matter the experiment, we always observed some\n",
      "errors on especially difficult images. That is for example\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:17:32.026202Z",
     "start_time": "2025-01-13T23:17:31.431604Z"
    }
   },
   "cell_type": "code",
   "source": "rag.invoke(query={\"question\":\"What is my conclusion in my project report?\"})[\"answer\"]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, but this document does not contain your project report, therefore I cannot answer your question.  The provided text is about GPT-4o and related articles.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
