{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code only works on google collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTUZqs8PS1vB"
   },
   "source": [
    "# Colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-11T16:47:40.263292Z",
     "iopub.status.busy": "2025-01-11T16:47:40.262975Z",
     "iopub.status.idle": "2025-01-11T16:47:41.212766Z",
     "shell.execute_reply": "2025-01-11T16:47:41.211970Z",
     "shell.execute_reply.started": "2025-01-11T16:47:40.263253Z"
    },
    "id": "YdTg8RdiTLMg",
    "outputId": "9c233b85-44d7-41d0-ecb2-193eeeffdacb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: cannot change to 'ColBERT/': No such file or directory\n",
      "Cloning into 'ColBERT'...\n",
      "remote: Enumerating objects: 2835, done.\u001b[K\n",
      "remote: Counting objects: 100% (1179/1179), done.\u001b[K\n",
      "remote: Compressing objects: 100% (351/351), done.\u001b[K\n",
      "remote: Total 2835 (delta 957), reused 829 (delta 828), pack-reused 1656 (from 2)\u001b[K\n",
      "Receiving objects: 100% (2835/2835), 2.07 MiB | 20.56 MiB/s, done.\n",
      "Resolving deltas: 100% (1788/1788), done.\n"
     ]
    }
   ],
   "source": [
    "!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git\n",
    "import sys; sys.path.insert(0, 'ColBERT/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abnEn154KTV7"
   },
   "source": [
    "## Loading Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-11T16:47:44.007154Z",
     "iopub.status.busy": "2025-01-11T16:47:44.006868Z",
     "iopub.status.idle": "2025-01-11T16:48:02.035709Z",
     "shell.execute_reply": "2025-01-11T16:48:02.034670Z",
     "shell.execute_reply.started": "2025-01-11T16:47:44.007134Z"
    },
    "id": "IJOSVNE-TRdQ",
    "outputId": "fa44e752-0c1a-4bbd-b31d-bbe49262ef97",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-24.3.1\n",
      "Obtaining file:///kaggle/working/ColBERT\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting bitarray (from colbert-ai==0.2.20)\n",
      "  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (3.2.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (2.2.5)\n",
      "Collecting git-python (from colbert-ai==0.2.20)\n",
      "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
      "Collecting python-dotenv (from colbert-ai==0.2.20)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (1.11.1.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (4.66.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (4.44.2)\n",
      "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (5.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->colbert-ai==0.2.20) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (6.0.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (8.1.7)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python->colbert-ai==0.2.20) (3.1.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (0.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->colbert-ai==0.2.20) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->colbert-ai==0.2.20) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (2024.8.30)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python->colbert-ai==0.2.20) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.20) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->colbert-ai==0.2.20) (1.16.0)\n",
      "Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
      "Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: bitarray, python-dotenv, git-python, colbert-ai\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of colbert-ai==0.2.20 from file:///kaggle/working/ColBERT (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for colbert-ai\n",
      "Successfully installed bitarray-3.0.0 colbert-ai git-python-1.0.3 python-dotenv-1.0.1\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    !pip install -U pip\n",
    "    !pip install -e ColBERT/\n",
    "    !pip install faiss-gpu torch\n",
    "except Exception:\n",
    "  import sys; sys.path.insert(0, 'ColBERT/')\n",
    "  try:\n",
    "    from colbert import Indexer, Searcher\n",
    "  except Exception:\n",
    "    print(\"If you're running outside Colab, use conda or install with pip, but it will be lower and less stable\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:26.172779Z",
     "iopub.status.busy": "2025-01-11T16:48:26.172469Z",
     "iopub.status.idle": "2025-01-11T16:48:32.019897Z",
     "shell.execute_reply": "2025-01-11T16:48:32.019197Z",
     "shell.execute_reply.started": "2025-01-11T16:48:26.172755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import colbert\n",
    "from colbert import Indexer, Searcher\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:34.613559Z",
     "iopub.status.busy": "2025-01-11T16:48:34.612784Z",
     "iopub.status.idle": "2025-01-11T16:48:35.600422Z",
     "shell.execute_reply": "2025-01-11T16:48:35.599764Z",
     "shell.execute_reply.started": "2025-01-11T16:48:34.613503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:37.892505Z",
     "iopub.status.busy": "2025-01-11T16:48:37.891818Z",
     "iopub.status.idle": "2025-01-11T16:48:44.096050Z",
     "shell.execute_reply": "2025-01-11T16:48:44.095126Z",
     "shell.execute_reply.started": "2025-01-11T16:48:37.892455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1357b3cfab547d699f0aef476ed0486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bdbc634da7455cad8346b70ad70440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eac5c4fc352413491c730a0bff70d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/187k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11271b5d89b448e5a6ad85cd7e86867a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c730c79f3dc4d6ba278e2239978768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4470380b8cf34b709b2ff9c1d9984b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/35.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da04854a3f34336b8b7e22828975a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/40181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bdd7855cca41438eddc4bb05049b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1d68228de646ab81fa7eca6c9934db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8fcc617aa4404e99c8e3483a382e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/41 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60169807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_qa = load_dataset(\"enelpol/rag-mini-bioasq\", \"question-answer-passages\")[\"test\"]\n",
    "ds_corpus = load_dataset(\"enelpol/rag-mini-bioasq\", \"text-corpus\")[\"test\"]\n",
    "\n",
    "# only keep ds_qa rows with 3 items or more because we use 3 by default in our case\n",
    "ds_qa = ds_qa.filter(lambda x: len(x[\"relevant_passage_ids\"]) >= 3)\n",
    "\n",
    "ds_qa.to_csv(\"../test_datasets/rag-mini-bioasq/qa/qa.csv\")\n",
    "ds_corpus.to_csv(\"../test_datasets/rag-mini-bioasq/corpus/corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:48.157426Z",
     "iopub.status.busy": "2025-01-11T16:48:48.157052Z",
     "iopub.status.idle": "2025-01-11T16:48:48.782414Z",
     "shell.execute_reply": "2025-01-11T16:48:48.781484Z",
     "shell.execute_reply.started": "2025-01-11T16:48:48.157397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_df = pd.read_csv(\"../test_datasets/rag-mini-bioasq/qa/qa.csv\")\n",
    "corpus_df = pd.read_csv(\"../test_datasets/rag-mini-bioasq/corpus/corpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:55.207468Z",
     "iopub.status.busy": "2025-01-11T16:48:55.207011Z",
     "iopub.status.idle": "2025-01-11T16:48:55.215954Z",
     "shell.execute_reply": "2025-01-11T16:48:55.214892Z",
     "shell.execute_reply.started": "2025-01-11T16:48:55.207420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collection = corpus_df['passage'].tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "34275e1f90094dc99c864f2ca595b17d",
      "7715a5c263d94e33bfdab21c473a0f59",
      "7441cf8e123243a5b50bf8cc8740e469",
      "187afcd71b724aabae532d0701f6ae28",
      "3651cb0866f14b29a09b3b5e37fe931a",
      "d85affd4b361473b83a859f922fbd956",
      "2f18b59873504eff8fc507022bea0155",
      "a6b8e2511fcb4759b226996973847b00",
      "f1d7d3b07dc841a4baa970eba528ade0",
      "ecf269fc78de4e7a9fe775ef8640888e",
      "f8d39ec49b3c4764a3c63ccfd7d136f6"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-01-11T16:48:58.851976Z",
     "iopub.status.busy": "2025-01-11T16:48:58.851688Z",
     "iopub.status.idle": "2025-01-11T16:59:56.263838Z",
     "shell.execute_reply": "2025-01-11T16:59:56.262777Z",
     "shell.execute_reply.started": "2025-01-11T16:48:58.851954Z"
    },
    "id": "4YwxqVMOT94o",
    "outputId": "d9bbfbec-8ee3-4691-9f98-4b8c75e168d9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Run context.\n",
      "Configured ColBERT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02780076a25240febb2fb0aab97a34e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Indexer.\n",
      "\n",
      "\n",
      "[Jan 11, 16:48:59] #> Creating directory /kaggle/working/experiments/rag_bioasq/indexes/rag_bioasq_index \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "#> Joined...\n",
      "Indexing complete!\n"
     ]
    }
   ],
   "source": [
    "# Configuration for indexing\n",
    "checkpoint = 'colbert-ir/colbertv2.0'\n",
    "index_name = 'rag_bioasq_index'\n",
    "doc_maxlen = 300                            # Maximum document length\n",
    "nbits = 2                                   # Encodage en 2 bits pour la compression\n",
    "\n",
    "# Index documents\n",
    "#   nranks=1: number of machine on which we execute\n",
    "#   experiment='movie_plots': name of the experiment\n",
    "with Run().context(RunConfig(nranks=1, experiment='rag_bioasq')):\n",
    "    print(\"Initialized Run context.\")\n",
    "    \n",
    "    # Configuration Colbert (kmeans_niters = nb itération algo kmean)\n",
    "    # Kmeans is used to group vectors into clusters => reduce the storage size (because we only store the centroids of the clusters) and faster because we just compare the distance between centroid and query\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4)\n",
    "    print(\"Configured ColBERT.\")\n",
    "    \n",
    "    # Initialization indexer\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    print(\"Initialized Indexer.\")\n",
    "    \n",
    "    # Index the collection\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)\n",
    "    print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul performance RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:04:39.633037Z",
     "iopub.status.busy": "2025-01-11T17:04:39.632523Z",
     "iopub.status.idle": "2025-01-11T17:04:39.638999Z",
     "shell.execute_reply": "2025-01-11T17:04:39.637957Z",
     "shell.execute_reply.started": "2025-01-11T17:04:39.633011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This function allows you to calculate the performance of the RAG on the retrieval part\n",
    "def test_retrieval(ds_qa, retrieve_function):\n",
    "    total_num_documents_considered = 0\n",
    "    num_valid_docs = 0\n",
    "    \n",
    "    for test_item in tqdm(ds_qa):\n",
    "        question = test_item[\"question\"]\n",
    "        expected_documents_ids = test_item[\"relevant_passage_ids\"]\n",
    "\n",
    "        response = retrieve_function(question, k=3)\n",
    "\n",
    "        ids = response[0]\n",
    "\n",
    "        num_documents_considered = min(len(expected_documents_ids), len(ids))\n",
    "        total_num_documents_considered += num_documents_considered\n",
    "\n",
    "        for id in ids:\n",
    "            if corpus_df['id'].iloc[id] in expected_documents_ids:\n",
    "                num_valid_docs += 1     \n",
    "        \n",
    "    return num_valid_docs / total_num_documents_considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:04:13.382559Z",
     "iopub.status.busy": "2025-01-11T17:04:13.382091Z",
     "iopub.status.idle": "2025-01-11T17:04:27.944112Z",
     "shell.execute_reply": "2025-01-11T17:04:27.943002Z",
     "shell.execute_reply.started": "2025-01-11T17:04:13.382518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 17:04:14] #> Loading codec...\n",
      "[Jan 11, 17:04:14] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ColBERT/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 17:04:14] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 17:04:14] #> Loading IVF...\n",
      "[Jan 11, 17:04:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ColBERT/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n",
      "100%|██████████| 2/2 [00:00<00:00, 884.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 17:04:14] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/kaggle/working/ColBERT/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "/kaggle/working/ColBERT/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(residuals_path, map_location='cpu')\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.93it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b40fc4172d4ef7901d64520d07010c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ColBERT/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Describe the mechanism of action of ibalizumab., \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6235,  1996,  7337,  1997,  2895,  1997, 21307, 11475,\n",
      "         9759,  2863,  2497,  1012,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from colbert import Searcher\n",
    "\n",
    "with Run().context(RunConfig(experiment=\"rag_bioasq\")):\n",
    "    searcher = Searcher(index=\"rag_bioasq_index\", collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "score = test_retrieval(ds_qa, searcher.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:04:50.652550Z",
     "iopub.status.busy": "2025-01-11T17:04:50.652174Z",
     "iopub.status.idle": "2025-01-11T17:04:50.657205Z",
     "shell.execute_reply": "2025-01-11T17:04:50.656506Z",
     "shell.execute_reply.started": "2025-01-11T17:04:50.652523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG score: 0.7887323943661971\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAG score: {score}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6455580,
     "sourceId": 10424263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "187afcd71b724aabae532d0701f6ae28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecf269fc78de4e7a9fe775ef8640888e",
      "placeholder": "​",
      "style": "IPY_MODEL_f8d39ec49b3c4764a3c63ccfd7d136f6",
      "value": " 1.63k/1.63k [00:00&lt;00:00, 34.6kB/s]"
     }
    },
    "2f18b59873504eff8fc507022bea0155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34275e1f90094dc99c864f2ca595b17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7715a5c263d94e33bfdab21c473a0f59",
       "IPY_MODEL_7441cf8e123243a5b50bf8cc8740e469",
       "IPY_MODEL_187afcd71b724aabae532d0701f6ae28"
      ],
      "layout": "IPY_MODEL_3651cb0866f14b29a09b3b5e37fe931a"
     }
    },
    "3651cb0866f14b29a09b3b5e37fe931a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7441cf8e123243a5b50bf8cc8740e469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6b8e2511fcb4759b226996973847b00",
      "max": 1633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1d7d3b07dc841a4baa970eba528ade0",
      "value": 1633
     }
    },
    "7715a5c263d94e33bfdab21c473a0f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d85affd4b361473b83a859f922fbd956",
      "placeholder": "​",
      "style": "IPY_MODEL_2f18b59873504eff8fc507022bea0155",
      "value": "artifact.metadata: 100%"
     }
    },
    "a6b8e2511fcb4759b226996973847b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d85affd4b361473b83a859f922fbd956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecf269fc78de4e7a9fe775ef8640888e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1d7d3b07dc841a4baa970eba528ade0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8d39ec49b3c4764a3c63ccfd7d136f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
