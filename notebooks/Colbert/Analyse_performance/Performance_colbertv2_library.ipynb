{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"34275e1f90094dc99c864f2ca595b17d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7715a5c263d94e33bfdab21c473a0f59","IPY_MODEL_7441cf8e123243a5b50bf8cc8740e469","IPY_MODEL_187afcd71b724aabae532d0701f6ae28"],"layout":"IPY_MODEL_3651cb0866f14b29a09b3b5e37fe931a"}},"7715a5c263d94e33bfdab21c473a0f59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d85affd4b361473b83a859f922fbd956","placeholder":"​","style":"IPY_MODEL_2f18b59873504eff8fc507022bea0155","value":"artifact.metadata: 100%"}},"7441cf8e123243a5b50bf8cc8740e469":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6b8e2511fcb4759b226996973847b00","max":1633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1d7d3b07dc841a4baa970eba528ade0","value":1633}},"187afcd71b724aabae532d0701f6ae28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecf269fc78de4e7a9fe775ef8640888e","placeholder":"​","style":"IPY_MODEL_f8d39ec49b3c4764a3c63ccfd7d136f6","value":" 1.63k/1.63k [00:00&lt;00:00, 34.6kB/s]"}},"3651cb0866f14b29a09b3b5e37fe931a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d85affd4b361473b83a859f922fbd956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f18b59873504eff8fc507022bea0155":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6b8e2511fcb4759b226996973847b00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1d7d3b07dc841a4baa970eba528ade0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecf269fc78de4e7a9fe775ef8640888e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d39ec49b3c4764a3c63ccfd7d136f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10424263,"sourceType":"datasetVersion","datasetId":6455580}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Colbert","metadata":{"id":"mTUZqs8PS1vB"}},{"cell_type":"code","source":"!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT.git\nimport sys; sys.path.insert(0, 'ColBERT/')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdTg8RdiTLMg","outputId":"9c233b85-44d7-41d0-ecb2-193eeeffdacb","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:47:40.262975Z","iopub.execute_input":"2025-01-11T16:47:40.263292Z","iopub.status.idle":"2025-01-11T16:47:41.212766Z","shell.execute_reply.started":"2025-01-11T16:47:40.263253Z","shell.execute_reply":"2025-01-11T16:47:41.211970Z"}},"outputs":[{"name":"stdout","text":"fatal: cannot change to 'ColBERT/': No such file or directory\nCloning into 'ColBERT'...\nremote: Enumerating objects: 2835, done.\u001b[K\nremote: Counting objects: 100% (1179/1179), done.\u001b[K\nremote: Compressing objects: 100% (351/351), done.\u001b[K\nremote: Total 2835 (delta 957), reused 829 (delta 828), pack-reused 1656 (from 2)\u001b[K\nReceiving objects: 100% (2835/2835), 2.07 MiB | 20.56 MiB/s, done.\nResolving deltas: 100% (1788/1788), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Si on run en dehors de collab regarder le readme (explique comment import sur conda)","metadata":{"id":"abnEn154KTV7"}},{"cell_type":"code","source":"try:\n    import google.colab\n    !pip install -U pip\n    !pip install -e ColBERT/\n    !pip install faiss-gpu torch\nexcept Exception:\n  import sys; sys.path.insert(0, 'ColBERT/')\n  try:\n    from colbert import Indexer, Searcher\n  except Exception:\n    print(\"If you're running outside Colab, please make sure you install ColBERT in conda following the instructions in our README. You can also install (as above) with pip but it may install slower or less stable faiss or torch dependencies. Conda is recommended.\")\n    assert False","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJOSVNE-TRdQ","outputId":"fa44e752-0c1a-4bbd-b31d-bbe49262ef97","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:47:44.006868Z","iopub.execute_input":"2025-01-11T16:47:44.007154Z","iopub.status.idle":"2025-01-11T16:48:02.035709Z","shell.execute_reply.started":"2025-01-11T16:47:44.007134Z","shell.execute_reply":"2025-01-11T16:48:02.034670Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\nDownloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-24.3.1\nObtaining file:///kaggle/working/ColBERT\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting bitarray (from colbert-ai==0.2.20)\n  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (3.2.0)\nRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (2.2.5)\nCollecting git-python (from colbert-ai==0.2.20)\n  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\nCollecting python-dotenv (from colbert-ai==0.2.20)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (1.11.1.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (1.13.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (4.66.5)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (4.44.2)\nRequirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.20) (5.10.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->colbert-ai==0.2.20) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.20) (6.0.2)\nRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (3.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.20) (8.1.7)\nRequirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python->colbert-ai==0.2.20) (3.1.43)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert-ai==0.2.20) (0.19.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert-ai==0.2.20) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->colbert-ai==0.2.20) (4.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->colbert-ai==0.2.20) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.20) (2024.8.30)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python->colbert-ai==0.2.20) (4.0.11)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert-ai==0.2.20) (2024.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.20) (5.0.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->colbert-ai==0.2.20) (1.16.0)\nDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\nDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: bitarray, python-dotenv, git-python, colbert-ai\n\u001b[33m  DEPRECATION: Legacy editable install of colbert-ai==0.2.20 from file:///kaggle/working/ColBERT (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n\u001b[0m  Running setup.py develop for colbert-ai\nSuccessfully installed bitarray-3.0.0 colbert-ai git-python-1.0.3 python-dotenv-1.0.1\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import colbert\nfrom colbert import Indexer, Searcher\nfrom colbert.infra import Run, RunConfig, ColBERTConfig\nfrom colbert.data import Queries, Collection","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:26.172469Z","iopub.execute_input":"2025-01-11T16:48:26.172779Z","iopub.status.idle":"2025-01-11T16:48:32.019897Z","shell.execute_reply.started":"2025-01-11T16:48:26.172755Z","shell.execute_reply":"2025-01-11T16:48:32.019197Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Chargement dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:34.612784Z","iopub.execute_input":"2025-01-11T16:48:34.613559Z","iopub.status.idle":"2025-01-11T16:48:35.600422Z","shell.execute_reply.started":"2025-01-11T16:48:34.613503Z","shell.execute_reply":"2025-01-11T16:48:35.599764Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"ds_qa = load_dataset(\"enelpol/rag-mini-bioasq\", \"question-answer-passages\")[\"test\"]\nds_corpus = load_dataset(\"enelpol/rag-mini-bioasq\", \"text-corpus\")[\"test\"]\n\n# only keep ds_qa rows with 3 items or more because we use 3 by default in our case\nds_qa = ds_qa.filter(lambda x: len(x[\"relevant_passage_ids\"]) >= 3)\n\nds_qa.to_csv(\"../test_datasets/rag-mini-bioasq/qa/qa.csv\")\nds_corpus.to_csv(\"../test_datasets/rag-mini-bioasq/corpus/corpus.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:37.891818Z","iopub.execute_input":"2025-01-11T16:48:37.892505Z","iopub.status.idle":"2025-01-11T16:48:44.096050Z","shell.execute_reply.started":"2025-01-11T16:48:37.892455Z","shell.execute_reply":"2025-01-11T16:48:44.095126Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1357b3cfab547d699f0aef476ed0486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13bdbc634da7455cad8346b70ad70440"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/187k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eac5c4fc352413491c730a0bff70d45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4012 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11271b5d89b448e5a6ad85cd7e86867a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/707 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c730c79f3dc4d6ba278e2239978768d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/35.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4470380b8cf34b709b2ff9c1d9984b6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/40181 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da04854a3f34336b8b7e22828975a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/707 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bdd7855cca41438eddc4bb05049b91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d1d68228de646ab81fa7eca6c9934db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/41 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8fcc617aa4404e99c8e3483a382e6a"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"60169807"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\nqa_df = pd.read_csv(\"../test_datasets/rag-mini-bioasq/qa/qa.csv\")\ncorpus_df = pd.read_csv(\"../test_datasets/rag-mini-bioasq/corpus/corpus.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:48.157052Z","iopub.execute_input":"2025-01-11T16:48:48.157426Z","iopub.status.idle":"2025-01-11T16:48:48.782414Z","shell.execute_reply.started":"2025-01-11T16:48:48.157397Z","shell.execute_reply":"2025-01-11T16:48:48.781484Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Création de la collection","metadata":{}},{"cell_type":"code","source":"collection = corpus_df['passage'].tolist() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:55.207011Z","iopub.execute_input":"2025-01-11T16:48:55.207468Z","iopub.status.idle":"2025-01-11T16:48:55.215954Z","shell.execute_reply.started":"2025-01-11T16:48:55.207420Z","shell.execute_reply":"2025-01-11T16:48:55.214892Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Création indexer","metadata":{}},{"cell_type":"code","source":"# Configuration pour l'indexation\ncheckpoint = 'colbert-ir/colbertv2.0'\nindex_name = 'rag_bioasq_index'\ndoc_maxlen = 300                            # Longueur maximale des documents\nnbits = 2                                   # Encodage en 2 bits pour la compression\n\n# Indexer les documents\n#   nranks=1  :  nombre de machine sur laquel on execute\n#   experiment='movie_plots' : nom de l'expérience\nwith Run().context(RunConfig(nranks=1, experiment='rag_bioasq')):\n    print(\"Initialized Run context.\")\n    \n    # Configuration Colbert (kmeans_niters = nb itération algo kmean)\n    # Kmeans est utilisé pour regrouper les vecteurs en cluster => réduire la taille du stockage (car on stock que les centroides des cluster) et + rapide car on compare juste la distance entre centroïde et requète\n    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4)\n    print(\"Configured ColBERT.\")\n    \n    # Initialisation indexuer\n    indexer = Indexer(checkpoint=checkpoint, config=config)\n    print(\"Initialized Indexer.\")\n    \n    # Indexer la collection\n    indexer.index(name=index_name, collection=collection, overwrite=True)\n    print(\"Indexing complete!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["34275e1f90094dc99c864f2ca595b17d","7715a5c263d94e33bfdab21c473a0f59","7441cf8e123243a5b50bf8cc8740e469","187afcd71b724aabae532d0701f6ae28","3651cb0866f14b29a09b3b5e37fe931a","d85affd4b361473b83a859f922fbd956","2f18b59873504eff8fc507022bea0155","a6b8e2511fcb4759b226996973847b00","f1d7d3b07dc841a4baa970eba528ade0","ecf269fc78de4e7a9fe775ef8640888e","f8d39ec49b3c4764a3c63ccfd7d136f6"]},"id":"4YwxqVMOT94o","outputId":"d9bbfbec-8ee3-4691-9f98-4b8c75e168d9","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:48:58.851688Z","iopub.execute_input":"2025-01-11T16:48:58.851976Z","iopub.status.idle":"2025-01-11T16:59:56.263838Z","shell.execute_reply.started":"2025-01-11T16:48:58.851954Z","shell.execute_reply":"2025-01-11T16:59:56.262777Z"}},"outputs":[{"name":"stdout","text":"Initialized Run context.\nConfigured ColBERT.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02780076a25240febb2fb0aab97a34e2"}},"metadata":{}},{"name":"stdout","text":"Initialized Indexer.\n\n\n[Jan 11, 16:48:59] #> Creating directory /kaggle/working/experiments/rag_bioasq/indexes/rag_bioasq_index \n\n\n#> Starting...\n#> Joined...\nIndexing complete!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Calcul performance RAG","metadata":{}},{"cell_type":"code","source":"def test_retrieval(ds_qa, retrieve_function):\n    total_num_documents_considered = 0\n    num_valid_docs = 0\n    \n    for test_item in tqdm(ds_qa):\n        question = test_item[\"question\"]\n        expected_documents_ids = test_item[\"relevant_passage_ids\"]\n\n        response = retrieve_function(question, k=3)\n\n        ids = response[0]\n\n        num_documents_considered = min(len(expected_documents_ids), len(ids))\n        total_num_documents_considered += num_documents_considered\n\n        for id in ids:\n            if corpus_df['id'].iloc[id] in expected_documents_ids:\n                num_valid_docs += 1     \n        \n    return num_valid_docs / total_num_documents_considered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T17:04:39.632523Z","iopub.execute_input":"2025-01-11T17:04:39.633037Z","iopub.status.idle":"2025-01-11T17:04:39.638999Z","shell.execute_reply.started":"2025-01-11T17:04:39.633011Z","shell.execute_reply":"2025-01-11T17:04:39.637957Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from colbert import Searcher\n\nwith Run().context(RunConfig(experiment=\"rag_bioasq\")):\n    searcher = Searcher(index=\"rag_bioasq_index\", collection=collection)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T17:04:13.382091Z","iopub.execute_input":"2025-01-11T17:04:13.382559Z","iopub.status.idle":"2025-01-11T17:04:27.944112Z","shell.execute_reply.started":"2025-01-11T17:04:13.382518Z","shell.execute_reply":"2025-01-11T17:04:27.943002Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[Jan 11, 17:04:14] #> Loading codec...\n[Jan 11, 17:04:14] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/ColBERT/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler()\n/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  centroids = torch.load(centroids_path, map_location='cpu')\n/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n/kaggle/working/ColBERT/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[Jan 11, 17:04:14] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[Jan 11, 17:04:14] #> Loading IVF...\n[Jan 11, 17:04:14] #> Loading doclens...\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/ColBERT/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n100%|██████████| 2/2 [00:00<00:00, 884.97it/s]","output_type":"stream"},{"name":"stdout","text":"[Jan 11, 17:04:14] #> Loading codes and residuals...\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]/kaggle/working/ColBERT/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(codes_path, map_location='cpu')\n/kaggle/working/ColBERT/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(residuals_path, map_location='cpu')\n100%|██████████| 2/2 [00:00<00:00,  4.93it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/497 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b40fc4172d4ef7901d64520d07010c"}},"metadata":{}},{"name":"stderr","text":"/kaggle/working/ColBERT/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n","output_type":"stream"},{"name":"stdout","text":"\n#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n#> Input: Describe the mechanism of action of ibalizumab., \t\t True, \t\t None\n#> Output IDs: torch.Size([32]), tensor([  101,     1,  6235,  1996,  7337,  1997,  2895,  1997, 21307, 11475,\n         9759,  2863,  2497,  1012,   102,   103,   103,   103,   103,   103,\n          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n          103,   103], device='cuda:0')\n#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"score = test_retrieval(ds_qa, searcher.search)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"RAG score: {score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T17:04:50.652174Z","iopub.execute_input":"2025-01-11T17:04:50.652550Z","iopub.status.idle":"2025-01-11T17:04:50.657205Z","shell.execute_reply.started":"2025-01-11T17:04:50.652523Z","shell.execute_reply":"2025-01-11T17:04:50.656506Z"}},"outputs":[{"name":"stdout","text":"RAG score: 0.7887323943661971\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!zip -r experiments/rag_bioasq/indexes/rag_bioasq_index experiments","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}