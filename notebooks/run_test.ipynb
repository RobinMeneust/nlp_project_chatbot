{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T19:55:35.629479Z",
     "start_time": "2025-01-11T19:55:06.154181Z"
    }
   },
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from nlp_chat_bot.doc_loader.test_data_csv_loader import TestDataCSVLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from nlp_chat_bot.model.embedding.minilm import MiniLM\n",
    "from nlp_chat_bot.model.llm.gemma import Gemma\n",
    "from nlp_chat_bot.rag.classic_rag import ClassicRAG\n",
    "from nlp_chat_bot.rag.query_translation_rag_decomposition import QueryTranslationRAGDecomposition\n",
    "from nlp_chat_bot.rag.query_translation_rag_fusion import QueryTranslationRAGFusion\n",
    "from nlp_chat_bot.vector_store.late_chunking_chroma_vector_store_builder import LateChunkingChromaVectorStoreBuilder\n",
    "from nlp_chat_bot.vector_store.naive_chunking_chroma_vector_store_builder import NaiveChunkingChromaVectorStoreBuilder\n",
    "from datasets import load_dataset, tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\nlp_project_chatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T19:55:44.008476Z",
     "start_time": "2025-01-11T19:55:35.629479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_qa = load_dataset(\"enelpol/rag-mini-bioasq\", \"question-answer-passages\")[\"test\"]\n",
    "ds_corpus = load_dataset(\"enelpol/rag-mini-bioasq\", \"text-corpus\")[\"test\"]\n",
    "\n",
    "# only keep ds_qa rows with 3 items or more because we use 3 by default in our case\n",
    "ds_qa = ds_qa.filter(lambda x: len(x[\"relevant_passage_ids\"]) >= 3)\n",
    "\n",
    "ds_qa.to_csv(\"../test_datasets/rag-mini-bioasq/qa/qa.csv\")\n",
    "ds_corpus.to_csv(\"../test_datasets/rag-mini-bioasq/corpus/corpus.csv\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 31.17ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 41/41 [00:00<00:00, 52.05ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60209989"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T19:55:44.387179Z",
     "start_time": "2025-01-11T19:55:44.371170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Datasets sizes:\")\n",
    "print(f\"ds_qa: {len(ds_qa)}\")\n",
    "print(f\"ds_corpus: {len(ds_corpus)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets sizes:\n",
      "ds_qa: 497\n",
      "ds_corpus: 40181\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T19:55:44.512579Z",
     "start_time": "2025-01-11T19:55:44.434357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(ds_qa.to_pandas().head(1))\n",
    "print(ds_corpus.to_pandas().head(1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          question  \\\n",
      "0  Describe the mechanism of action of ibalizumab.   \n",
      "\n",
      "                                              answer    id  \\\n",
      "0  Ibalizumab is a humanized monoclonal antibody ...  2835   \n",
      "\n",
      "                                relevant_passage_ids  \n",
      "0  [29675744, 24853313, 29689540, 21289125, 20698...  \n",
      "                                             passage    id\n",
      "0  New data on viruses isolated from patients wit...  9797\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T20:13:50.657032Z",
     "start_time": "2025-01-11T20:13:49.215604Z"
    }
   },
   "source": [
    "from nlp_chat_bot.model.embedding.late_chunking_embedding import LateChunkingEmbedding\n",
    "\n",
    "\n",
    "corpus_path = \"../test_datasets/rag-mini-bioasq/corpus\"\n",
    "vector_store_path = \"../test_chromadb\"\n",
    "model_download_path = \"../models\"\n",
    "reload_vector_store = True # Add non existing documents\n",
    "reset_vector_store = False # Remove previous documents\n",
    "\n",
    "test_params = {\n",
    "    \"splitter\": {\n",
    "        \"class\": RecursiveCharacterTextSplitter,\n",
    "        \"params\": {\n",
    "            \"chunk_size\": 1000,\n",
    "            \"chunk_overlap\": 0,\n",
    "            \"add_start_index\": True,\n",
    "        }\n",
    "    },\n",
    "    \"embedding_function\": {\n",
    "        \"class\": MiniLM\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"class\": ChatGoogleGenerativeAI,\n",
    "        \"params\": {\n",
    "            \"model\": \"gemini-1.5-flash\"\n",
    "        }\n",
    "        # \"class\": Gemma,\n",
    "        # \"params\": {\n",
    "        #     \"model_download_path\": model_download_path\n",
    "        # }\n",
    "    },\n",
    "    \"rag\": {\n",
    "        \"class\": ClassicRAG\n",
    "    },\n",
    "    \"vector_store_builder\": {\n",
    "        \"class\": NaiveChunkingChromaVectorStoreBuilder\n",
    "    }\n",
    "}\n",
    "# splitter = None\n",
    "splitter = test_params[\"splitter\"][\"class\"](\n",
    "    chunk_size=test_params[\"splitter\"][\"params\"][\"chunk_size\"],  # chunk size (characters)\n",
    "    chunk_overlap=test_params[\"splitter\"][\"params\"][\"chunk_overlap\"],  # chunk overlap (characters)\n",
    "    add_start_index=test_params[\"splitter\"][\"params\"][\"add_start_index\"],  # track index in original document\n",
    ")\n",
    "\n",
    "embedding_function = test_params[\"embedding_function\"][\"class\"](model_download_path=model_download_path)\n",
    "# vector_store = test_params[\"vector_store_builder\"][\"class\"](corpus_path, embedding_function, vector_store_path, splitter, document_loader=TestDataCSVLoader()).build(reload_vector_store, reset_vector_store)\n",
    "vector_store = test_params[\"vector_store_builder\"][\"class\"](corpus_path, embedding_function, vector_store_path, splitter, document_loader=TestDataCSVLoader()).build(False, False)\n",
    "llm = model_name=test_params[\"llm\"][\"class\"](**(test_params[\"llm\"][\"params\"]))\n",
    "rag = test_params[\"rag\"][\"class\"](vector_store, llm=llm)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\nlp_project_chatbot\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T20:13:50.672663Z",
     "start_time": "2025-01-11T20:13:50.657032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test if our Llama installation supports GPU\n",
    "\n",
    "# import os\n",
    "# from llama_cpp.llama_cpp import load_shared_library\n",
    "# import llama_cpp\n",
    "# \n",
    "# llama_root_path_module = os.path.dirname(llama_cpp.__file__)\n",
    "# import pathlib\n",
    "# \n",
    "# def is_gpu_available_v3() -> bool:\n",
    "# \n",
    "#     lib = load_shared_library('llama',pathlib.Path(llama_root_path_module+'/lib'))\n",
    "#     return bool(lib.llama_supports_gpu_offload())\n",
    "# \n",
    "# print(is_gpu_available_v3())"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T20:13:50.704360Z",
     "start_time": "2025-01-11T20:13:50.688287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_retrieval(ds_qa, retrieve_function):\n",
    "    total_num_documents_considered = 0\n",
    "    num_valid_docs = 0\n",
    "    for test_item in tqdm(ds_qa):\n",
    "        question = test_item[\"question\"]\n",
    "        expected_documents_ids = test_item[\"relevant_passage_ids\"]\n",
    "        \n",
    "        response = retrieve_function(state = {\"question\": question, \"context\": []})\n",
    "        docs_retrieved = response[\"context\"]\n",
    "        num_documents_considered = min(len(expected_documents_ids), len(docs_retrieved))\n",
    "        \n",
    "        \n",
    "        # print(\"Question:\",question)\n",
    "        \n",
    "        # if it's a dict of docs (e.g. with QueryTranslationRAGDecomposition)\n",
    "        if isinstance(docs_retrieved, dict):\n",
    "            for question, docs in docs_retrieved.items():\n",
    "                total_num_documents_considered += len(docs)\n",
    "                for doc in docs:\n",
    "                    if doc.metadata[\"id\"] in expected_documents_ids:\n",
    "                        num_valid_docs += 1\n",
    "        else:\n",
    "            total_num_documents_considered += num_documents_considered\n",
    "            # print(\"Expected:\",expected_documents_ids,\"Got:\",[doc.metadata[\"id\"] for doc in docs_retrieved])\n",
    "            # print(\"Expected:\",expected_documents_ids)\n",
    "            for doc in docs_retrieved:\n",
    "                # print(\"Got:\",doc.metadata[\"id\"])\n",
    "                if int(doc.metadata[\"id\"]) in expected_documents_ids:\n",
    "                    num_valid_docs += 1\n",
    "        \n",
    "        \n",
    "    return num_valid_docs / total_num_documents_considered"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T20:13:53.818946Z",
     "start_time": "2025-01-11T20:13:50.719994Z"
    }
   },
   "cell_type": "code",
   "source": "score = test_retrieval(ds_qa, rag.retrieve)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [00:03<00:00, 161.19it/s]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T20:13:53.853271Z",
     "start_time": "2025-01-11T20:13:53.834571Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"RAG score: {score}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG score: 0.5372233400402414\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
